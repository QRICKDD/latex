We review several typical white-box adversarial attacks in this subsection.The Fast Gradient Sign Method (FGSM) assumes the linear behavior in high-dimensional space is sufficient to generate adversarial inputs. Therefore, it constructs adversarial samples by applying a first-order approximation of the loss function. An adversarial example can be generated within one-step update.As an iterative version of FGSM, the Projected Gradient Descent (PGD) selects the original sample as a starting point and generates adversarial examples with multiple steps. It is a powerful adversarial attack method and is therefore often used as a baseline attack for evaluating defense.Inspired by the momentum optimizer, Dong \textit{et al.} proposed to integrate the momentum memory into the iterative process and derived a new iterative algorithm, termed momentum iterative FGSM (MI-FGSM). Generally, momentum-based adversarial examples could well transfer to black-box models.DeepFool is also an iterative attack method, which was proposed to generate an adversarial example with the minimum perturbation on the decision boundary of a classifier.The Carlini & Wagner (CW) attack method takes a Lagrangian form and adopts Adam for optimization.